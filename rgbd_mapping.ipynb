{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 - Imports and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyFM.mesh import TriMesh\n",
    "from pyFM.functional import FunctionalMapping\n",
    "\n",
    "import meshplot as mp\n",
    "\n",
    "def plot_mesh(myMesh,cmap=None):\n",
    "    mp.plot(myMesh.vertlist, myMesh.facelist,c=cmap)\n",
    "    \n",
    "def double_plot(myMesh1,myMesh2,cmap1=None,cmap2=None):\n",
    "    d = mp.subplot(myMesh1.vertlist, myMesh1.facelist, c=cmap1, s=[2, 2, 0])\n",
    "    mp.subplot(myMesh2.vertlist, myMesh2.facelist, c=cmap2, s=[2, 2, 1], data=d)\n",
    "\n",
    "def visu(vertices):\n",
    "    min_coord,max_coord = np.min(vertices,axis=0,keepdims=True),np.max(vertices,axis=0,keepdims=True)\n",
    "    cmap = (vertices-min_coord)/(max_coord-min_coord)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Loading and processing a mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Mesh methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TriMesh class can be created from a path (to a .off or a .obj file) or simply an array of vertices and an optional array of faces.\n",
    "\n",
    "The mesh can be centered, area-normalized, rotated or translated when loading.\n",
    "\n",
    "\n",
    "Vertices and faces are stored in the 'vertlist' and 'facelist' attributes. One can also use 'mesh.vertices' and 'mesh.faces' to access them. While these notations can feel non-intuitive they result in clearer functions as it avoids expressions of the form ```mesh.vertices - vertices```.\n",
    "\n",
    "A TriMesh class possess multiple attributes like edges, per-face area, per-vertex area, per-face normals, per-vertex normals, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1 = TriMesh('data/2/target.off', area_normalize=True, center=False)\n",
    "mesh2 = TriMesh(mesh1.vertlist, mesh1.facelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes are computed on the fly and cached\n",
    "edges = mesh1.edges\n",
    "\n",
    "area = mesh1.area\n",
    "\n",
    "face_areas = mesh1.face_areas\n",
    "vertex_areas = mesh1.vertex_areas\n",
    "face_normals = mesh1.normals\n",
    "\n",
    "# AREA WEIGHTED VERTEX NORMALS\n",
    "vertex_normals_a = mesh1.vertex_normals\n",
    "\n",
    "# UNIFORM WEIGHTED VERTEX NORMALS\n",
    "mesh1.set_vertex_normal_weighting('uniform')\n",
    "vertex_normals_u = mesh1.vertex_normals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodesics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose three versions to compute geodesics :\n",
    "- Heat method - based on [potpourri3d](https://github.com/nmwsharp/potpourri3d) using robust laplacian (recommended)\n",
    "- Heat method - pure python implementation from pyFM (not robust but control on the whole code)\n",
    "- Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geodesic distance from a given index\n",
    "# Set robust to False to obtain result from the Python implementation\n",
    "dists = mesh1.geod_from(1000, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S1_geod = mesh1.get_geodesic(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectrum of the LBO can be computed easily.\n",
    "\n",
    "Eigenvalues and eigenvectors are stored in the ```mesh.eigenvalues``` and ```mesh.eigenvectors``` attributes.\n",
    "\n",
    "Gradient and divergence can be computed using the associated methods. Using the ```mesh.project``` and ```mesh.unproject``` functions allows to switch between seeing a function in the LBO basis or on the complete shape.\n",
    "\n",
    "The squared $L^2$ norm and $H^1_0$ norm can be computed via the ```mesh.l2_sqnorm``` and ```mesh.h1_sqnorm``` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default does not use the intrinsic delaunay Laplacian\n",
    "mesh1.process(k=100, intrinsic=False, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a figure twice as wide as it is tall\n",
    "i = 0\n",
    "d = mp.subplot(mesh1.vertlist, mesh1.facelist, c=mesh1.eigenvectors[:,i], s=[1, 10, 0])\n",
    "for i in range(1,10):\n",
    "    d = mp.subplot(mesh1.vertlist, mesh1.facelist, c=mesh1.eigenvectors[:,i], s=[1, 10, i], data=d)\n",
    "\n",
    "#d.save(\"myplottest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Computing the functional map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data (1/2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1 = TriMesh('data/2/target.off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data (2/2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#â™¦mesh2 = TriMesh('data/2022-11-23-CT/1_cropped_scaled_freeze_translated.off')\n",
    "mesh2 = TriMesh('data/2/source.off')\n",
    "#mesh2 = TriMesh('data/2022-11-23-CT/CT_cleaned_03_removed_isolated_decimated.off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mesh 1 : {mesh1.n_vertices:4d} vertices, {mesh1.n_faces:5d} faces\\n'\n",
    "      f'Mesh 2 : {mesh2.n_vertices:4d} vertices, {mesh2.n_faces:5d} faces')\n",
    "\n",
    "d = mp.subplot(mesh1.vertlist, mesh1.facelist, None, s=[2, 2, 0])\n",
    "mp.subplot(mesh2.vertlist, mesh2.facelist, None, s=[2, 2, 1], data=d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add correspondences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadLandmark = True\n",
    "if loadLandmark:\n",
    "    landmarks = np.loadtxt('data/18/landmarks.txt',dtype=int)[:8]  # loading 5 landmarks\n",
    "    display(landmarks)\n",
    "\n",
    "    landmarks_plot_CT = TriMesh(mesh1.vertlist[landmarks[:,0]])\n",
    "    landmarks_plot_RGBD = TriMesh(mesh2.vertlist[landmarks[:,1]])\n",
    "\n",
    "    #landmarks_plot_CT = TriMesh(mesh1.facelist[landmarks[:,0]])\n",
    "    #landmarks_plot_RGBD = TriMesh(mesh2.facelist[landmarks[:,1]])\n",
    "\n",
    "    print('Retrieved matching faces from CT & RGBD pointclouds')\n",
    "    \n",
    "else:\n",
    "     landmarks = []\n",
    "\n",
    "\n",
    "\n",
    "#d = mp.subplot(mesh1.vertlist, mesh1.facelist, None, s=[2, 2, 0])\n",
    "\n",
    "p1 = mp.plot(mesh1.vertlist, mesh1.facelist, None)\n",
    "p2 = mp.plot(mesh2.vertlist, mesh2.facelist, None)\n",
    "\n",
    "if loadLandmark:\n",
    "    color = c=np.random.rand(*landmarks_plot_CT.vertlist.shape)\n",
    "    p1.add_points(landmarks_plot_CT.vertlist, c = color, shading={\"point_size\": 0.3})\n",
    "    p2.add_points(landmarks_plot_RGBD.vertlist, c = color, shading={\"point_size\": 0.3})\n",
    "\n",
    "#i = 0\n",
    "#for vert in landmarks_plot_CT.vertlist:\n",
    "#    color = c=np.random.rand(3)\n",
    "#    p1.add_points(landmarks_plot_CT.vertlist[i], shading={\"point_size\": 15, \"point_color\": color})\n",
    "#    p2.add_points(landmarks_plot_RGBD.vertlist[i], shading={\"point_size\": 15, \"point_color\": color})\n",
    "#    i = i+1\n",
    "\n",
    "#p = mp.plot(landmarks_plot_CT.vertlist, landmarks_plot_CT.facelist, c = None, shading={\"point_size\": 15})\n",
    "#mp.subplot(landmarks_plot_RGBD.vertlist, landmarks_plot_RGBD.facelist, None, s=[2, 2, 3], data=d, shading={\"point_size\": 15})\n",
    "\n",
    "#d = mp.subplot(mesh1.vertlist, mesh1.facelist, c=mesh1.eigenvectors[:,i], s=[1, 10, i], data=d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing descriptors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_params = {\n",
    "    'n_ev': (25,25),  # Number of eigenvalues on source and Target\n",
    "    'landmarks': landmarks,  # loading 5 landmarks\n",
    "    'subsample_step': 5,  # In order not to use too many descriptors\n",
    "    'descr_type': 'HKS',  # WKS or HKS\n",
    "}\n",
    "\n",
    "\n",
    "model = FunctionalMapping(mesh1,mesh2)\n",
    "model.preprocess(**process_params,verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\Ss}{\\mathcal{S}}$\n",
    "$\\newcommand{\\uargmin}[1]{\\underset{#1}{\\text{argmin}}\\;}$\n",
    "$\\newcommand{\\uargmax}[1]{\\underset{#1}{\\text{argmax}}\\;}$\n",
    "$\\def\\*#1{\\mathbf{#1}}$\n",
    "\n",
    "In pyFM, we always consider functional maps $\\*C:\\Ss_1\\to\\Ss_2$ and pointwise maps $T:\\Ss_2\\to\\Ss_1$ going in opposite directions, with $\\*C$ always going from shape 1 to shape 2 !\n",
    "\n",
    "Optimization problem is\n",
    "\\begin{equation}\n",
    "\\uargmin{\\*C\\in\\RR^{k_2\\times k_1}} w_{descr}\\|\\*C\\*A - \\*B\\|^2 + w_{lap}\\|\\*C\\Delta_1 - \\Delta_2\\*C\\|^2 + w_{\\text{d- comm}}\\sum_i \\|\\*C\\Gamma_1^i - \\Gamma_2^i\\*C\\|^2 + w_{\\text{orient}}\\sum_i \\|\\*C\\Lambda_1^i - \\Lambda_2^i\\*C\\|^2\n",
    "\\end{equation}\n",
    "\n",
    "with $\\Gamma_1^i$ and $\\Gamma_2^i$ [multipliative operators](http://www.lix.polytechnique.fr/~maks/papers/fundescEG17.pdf) associated to the $i$-th descriptors, $\\Lambda_1^i$ and $\\Lambda_2^i$ [orientation preserving operators](https://arxiv.org/abs/1806.04455) associated to the $i$-th descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'w_descr': 1e0, #scaling for the descriptor preservation term\n",
    "    'w_lap': 1e-2, #scaling of the laplacian commutativity term\n",
    "    'w_dcomm': 1e-1, #scaling of the multiplicative operator commutativity\n",
    "    'w_orient': 0, #scaling of the orientation preservation term\n",
    "    #'orient_reversing':True, #Whether to use the orientation reversing term instead of the orientation preservation one\n",
    "    #'optinit':'zeros' #Initialization\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model.fit(**fit_params, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the associated point to point map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p2p_21 = model.get_p2p(n_jobs=1)\n",
    "cmap1 = visu(mesh1.vertlist); cmap2 = cmap1[p2p_21]\n",
    "double_plot(mesh1,mesh2,cmap1,cmap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Refining the Functional Map\n",
    "```model.FM``` returns the current state of functional map. One can change which one is returned by using ```model.change_FM_type(FM_type)```, as one can see below. \n",
    "\n",
    "**ICP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.icp_refine(verbose=True)\n",
    "p2p_21_icp = model.get_p2p()\n",
    "cmap1 = visu(mesh1.vertlist); cmap2 = cmap1[p2p_21_icp]\n",
    "double_plot(mesh1,mesh2,cmap1,cmap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zoomout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.change_FM_type('classic') # We refine the first computed map ('classic') or the icp-refined one ('icp')\n",
    "model.zoomout_refine(nit=15, step = 1, verbose=True)\n",
    "print(model.FM.shape)\n",
    "p2p_21_zo = model.get_p2p()\n",
    "cmap1 = visu(mesh1.vertlist); cmap2 = cmap1[p2p_21_zo]\n",
    "double_plot(mesh1,mesh2,cmap1,cmap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file in write mode\n",
    "with open(r'p2p_icp.txt', 'w') as p2p_icp:\n",
    "    for item in p2p_21_icp:\n",
    "        # write each item on a new line\n",
    "        p2p_icp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "# open file in write mode\n",
    "with open(r'p2p_zo.txt', 'w') as f_export_zo:\n",
    "    for item in p2p_21_zo:\n",
    "        # write each item on a new line\n",
    "        f_export_zo.write(\"%s\\n\" % item)\n",
    "    print('Done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4fdb5c5338a8fa7b742ce98cb975129d6aa57d42a9958c3fdc924baafbc05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
